{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to get decision tree which we use as our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../DecisionTree/CS5350HW1.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define D_t\n",
    "#for t=1,2,..,T\n",
    "    #find h_t whose weighted classification error is better than chance\n",
    "    #Compute a_t = 1/2ln((1-e_t)/e_t)\n",
    "    #Update D_t+1(i) = D_t(i)/Z_t*e^{-a_ty_ih_t(x_i)}\n",
    "#H_final = sgn(sum(a_th_t(x)))\n",
    "\n",
    "def Adaboost(D_t, iterations, s_train, full_attributes, attributes, purity_function):\n",
    "    classifiers = []\n",
    "    alphas = []\n",
    "    for i in range(iterations):\n",
    "        #print(\"Iteration:\", i)\n",
    "        root = createTree(s_train, attributes, full_attributes, purity_function, D_t, 1)\n",
    "        #print(root.label)\n",
    "        classifiers.append(copy.deepcopy(root))\n",
    "        error = findError(root, s_train, D_t, full_attributes)\n",
    "        a_t = 0.5*np.log((1-error)/error)\n",
    "        D_t_next = np.ones(len(s_train))\n",
    "        for trainInd in range(len(s_train)):\n",
    "            #travTree returns 1 if matched and 0 otherwise\n",
    "            pred = travTree(root, s_train[trainInd], full_attributes)\n",
    "            if(pred == 0):\n",
    "                D_t_next[trainInd] = D_t[trainInd]*np.e**(a_t)\n",
    "            else:\n",
    "                D_t_next[trainInd] = D_t[trainInd]*np.e**(-a_t)\n",
    "        #print(D_t_next)\n",
    "        Z_t = np.sum(D_t_next)\n",
    "        D_t_next = D_t_next/Z_t\n",
    "        #print(D_t)\n",
    "        #print(D_t_next)\n",
    "        #print(error)\n",
    "        #displayTree(root)\n",
    "        D_t = D_t_next\n",
    "        alphas.append(a_t)\n",
    "    return classifiers, alphas, D_t\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findError(root, s, D_t, full_attributes):\n",
    "  matched = 0\n",
    "  for i in range(len(s)):\n",
    "    #Note, (1-x) maps 0 -> 1 and 1 -> 0\n",
    "    matched += D_t[i]*(1-travTree(root, s[i], full_attributes))\n",
    "  return matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findModelAccuracy(s_test, classifiers, alphas, full_attributes):\n",
    "    matched = 0\n",
    "    for test in s_test:\n",
    "        h_f = computeHFinal(classifiers, alphas, test, full_attributes)\n",
    "        #print(h_f, test[len(test)-1])\n",
    "        if(h_f > 0 and convertStringToBinary(test[len(test)-1]) > 0):\n",
    "            matched += 1\n",
    "        elif(h_f < 0 and convertStringToBinary(test[len(test)-1]) < 0):\n",
    "             matched += 1\n",
    "    return matched/len(s_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHFinal(classifiers, alphas, x_i, full_attributes):\n",
    "    final = 0\n",
    "    for i in range(len(classifiers)):\n",
    "        #print(alphas[i])\n",
    "        #print(travTreeWithoutLabel(classifiers[i], x_i, full_attributes))\n",
    "        final += alphas[i]*travTreeWithoutLabel(classifiers[i], x_i, full_attributes)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStringToBinary(y_i):\n",
    "    if(y_i == \"yes\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much travTree, but now will return 1 for a yes label and -1 for a no label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travTreeWithoutLabel(root, datapoint, full_attr):\n",
    "  #Stopping Condition, root no children\n",
    "  if(len(root.children) == 0):\n",
    "    if(root.label == \"yes\"):\n",
    "      #print(\"matched\")\n",
    "      return 1\n",
    "    else:\n",
    "      #print(\"no match\")\n",
    "      return -1\n",
    "  #Otherwise, traverse down\n",
    "  curr_attr = root.label\n",
    "  do_numeric = False\n",
    "  if(full_attr[curr_attr] == \"numeric\"):\n",
    "    do_numeric = True\n",
    "  #print(\"current attribute: \", curr_attr)\n",
    "  atr_ind = list(full_attr.keys()).index(curr_attr)\n",
    "  for child in root.children:\n",
    "    if(do_numeric):\n",
    "      median = statistics.median(x[atr_ind] for x in root.s)\n",
    "      #print(\"numeric: \", median, \" \", datapoint[atr_ind])\n",
    "      if((datapoint[atr_ind] < median and child.parentVal==\"lower than median\") or (datapoint[atr_ind] >= median and child.parentVal==\"higher than median\")):\n",
    "        return travTreeWithoutLabel(child, datapoint, full_attr)\n",
    "    else:\n",
    "      if(child.parentVal == datapoint[atr_ind]):\n",
    "        #print(\"Going down on val: \", child.parentVal)\n",
    "        return travTreeWithoutLabel(child, datapoint, full_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterations = 20\n",
    "s_train = s_banktraining\n",
    "s_test = s_banktesting\n",
    "full_attributes = full_attributes_bank\n",
    "attributes = remaining_attributes_bank\n",
    "purity_function = GiniInd\n",
    "\n",
    "D_1 = np.ones(len(s_train))/len(s_train)\n",
    "\n",
    "classifiers, alphas = Adaboost(D_t=D_1, iterations=iterations, s_train=s_train, full_attributes=full_attributes, attributes=attributes, purity_function=purity_function)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(alphas)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T=500\n",
    "classifierArr = []\n",
    "alphaArr = []\n",
    "D_t = np.ones(len(s_train))/len(s_train)\n",
    "s_train = s_banktraining\n",
    "s_test = s_banktesting\n",
    "full_attributes = full_attributes_bank\n",
    "attributes = remaining_attributes_bank\n",
    "purity_function = GiniInd\n",
    "\n",
    "for i in range(1, T):\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(i)\n",
    "    classifiers, alphas, weights = Adaboost(D_t=D_t, iterations=1, s_train=s_train, full_attributes=full_attributes, attributes=attributes, purity_function=purity_function)\n",
    "    classifierArr.append(classifiers[0])\n",
    "    alphaArr.append(alphas[0])\n",
    "    D_t = weights\n",
    "    print(\"train:\", findModelAccuracy(s_test=s_train, classifiers=classifierArr, alphas=alphaArr, full_attributes=full_attributes))\n",
    "    print(\"test:\",findModelAccuracy(s_test=s_test, classifiers=classifierArr, alphas=alphaArr, full_attributes=full_attributes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
