{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Imports, including data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"VoW\", \"SoW\", \"CoW\", \"Entropy\", \"Label\"]\n",
    "bank_note_training = pd.read_csv(\"https://raw.githubusercontent.com/DoubekSeth/ToyDatasets/main/bank-note/train.csv\", header=None, names=attributes)\n",
    "bank_note_testing = pd.read_csv(\"https://raw.githubusercontent.com/DoubekSeth/ToyDatasets/main/bank-note/test.csv\", header=None, names=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_term_to_df(df):\n",
    "    rows = df.shape[0]\n",
    "    columns = df.shape[1]\n",
    "    ones = np.ones(rows)\n",
    "    #Need to check if actually need to insert\n",
    "    if(\"Bias Term\" not in df.columns):\n",
    "        df.insert(columns-1, \"Bias Term\", ones, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWeights0(hiddenLayer1, hiddenLayer2, data):\n",
    "    add_bias_term_to_df(data)\n",
    "    columns = data.shape[1]-1#Minus 1 from y labels\n",
    "    weights = {}\n",
    "    for i in range(1, hiddenLayer1):\n",
    "        weights[\"0\"+str(i)] = np.zeros(columns)\n",
    "    for j in range(1, hiddenLayer2):\n",
    "        weights[\"1\"+str(j)] = np.zeros(hiddenLayer1)\n",
    "    weights[\"21\"] = np.zeros(hiddenLayer2)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWeightsNormal(hiddenLayer1, hiddenLayer2, data):\n",
    "    add_bias_term_to_df(data)\n",
    "    columns = data.shape[1]-1#Minus 1 from y labels\n",
    "    weights = {}\n",
    "    for i in range(1, hiddenLayer1):\n",
    "        weights[\"0\"+str(i)] = np.random.randn(columns)\n",
    "    for j in range(1, hiddenLayer2):\n",
    "        weights[\"1\"+str(j)] = np.random.randn(hiddenLayer1)\n",
    "    weights[\"21\"] = np.random.randn(hiddenLayer2)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.power(np.e, -x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(pred, label, weights, firstLayerNodes, secondLayerNodes, hiddenLayer1, hiddenLayer2, data):\n",
    "    columns = data.shape[0]\n",
    "    wGrads = {}\n",
    "    nodeGrads = {}\n",
    "    #First pass\n",
    "    nodeGrads[\"y\"] = (pred - label) #dL/dy\n",
    "    wGrads[\"21\"] = nodeGrads[\"y\"]*secondLayerNodes #dL/dw2\n",
    "    #Second pass\n",
    "    nodeGrads[\"2\"] = nodeGrads[\"y\"]*weights[\"21\"] #dL/dZ2\n",
    "    for i in range(1, hiddenLayer2):\n",
    "        wGrads[\"1\"+str(i)] = nodeGrads[\"2\"][i]*secondLayerNodes[i]*(1-secondLayerNodes[i])*firstLayerNodes #dL/dw1\n",
    "    #Third pass\n",
    "    for j in range(1, hiddenLayer1):\n",
    "        nodeGrads[\"1\"+str(j)] = np.dot(np.multiply(nodeGrads[\"2\"], np.multiply(secondLayerNodes, 1-secondLayerNodes))[1:], [weights[\"1\"+str(a)][j] for a in range(1, hiddenLayer2)]) #dL/dZ1\n",
    "    for k in range(1, hiddenLayer1):\n",
    "        wGrads[\"0\"+str(k)] = nodeGrads[\"1\"+str(k)]*firstLayerNodes[k]*(1-firstLayerNodes[k])*np.array(data)\n",
    "    return wGrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningRate(gamma_0, alpha, t):\n",
    "    return gamma_0/(1+gamma_0/alpha*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNN(DF, weights, hiddenLayer1, hiddenLayer2):\n",
    "    add_bias_term_to_df(DF)\n",
    "    count = 0\n",
    "    for index, row in DF.iterrows():\n",
    "        label = row.iloc[-1]\n",
    "        data = row.iloc[:len(row)-1]\n",
    "        #Now, start the passes\n",
    "        firstLayerNodes = np.ones(1)\n",
    "        for i in range(1, hiddenLayer1):\n",
    "            w = weights[\"0\"+str(i)]\n",
    "            firstLayerNodes = np.append(firstLayerNodes, sigmoid(np.dot(w, data)))\n",
    "        #Second Pass\n",
    "        secondLayerNodes = np.ones(1)\n",
    "        for j in range(1, hiddenLayer2):\n",
    "            w = weights[\"1\"+str(j)]\n",
    "            secondLayerNodes = np.append(secondLayerNodes, sigmoid(np.dot(w, firstLayerNodes)))\n",
    "        #Final pass\n",
    "        pred = np.dot(weights[\"21\"], secondLayerNodes)\n",
    "        if(pred < 0.5 and label == 0 or pred >= 0 and label == 1):\n",
    "            count += 1\n",
    "    return count/DF.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLossNN(DF, weights, hiddenLayer1, hiddenLayer2):\n",
    "    add_bias_term_to_df(DF)\n",
    "    losses = 0\n",
    "    for index, row in DF.iterrows():\n",
    "        label = row.iloc[-1]\n",
    "        data = row.iloc[:len(row)-1]\n",
    "        #Now, start the passes\n",
    "        firstLayerNodes = np.ones(1)\n",
    "        for i in range(1, hiddenLayer1):\n",
    "            w = weights[\"0\"+str(i)]\n",
    "            firstLayerNodes = np.append(firstLayerNodes, sigmoid(np.dot(w, data)))\n",
    "        #Second Pass\n",
    "        secondLayerNodes = np.ones(1)\n",
    "        for j in range(1, hiddenLayer2):\n",
    "            w = weights[\"1\"+str(j)]\n",
    "            secondLayerNodes = np.append(secondLayerNodes, sigmoid(np.dot(w, firstLayerNodes)))\n",
    "        #Final pass\n",
    "        pred = np.dot(weights[\"21\"], secondLayerNodes)\n",
    "        l = 0.5*(pred-label)**2\n",
    "        losses += l\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(DF, weights, T, gamma_0, alpha, hiddenLayer1, hiddenLayer2, updateWeights=True, learningRate=learningRate):\n",
    "    add_bias_term_to_df(DF)\n",
    "    for epoch in range(T):\n",
    "        #print(epoch)\n",
    "        shuffled_data = DF.sample(frac=1)\n",
    "        for index, row in shuffled_data.iterrows():\n",
    "            label = row.iloc[-1]\n",
    "            data = row.iloc[:len(row)-1]\n",
    "            #Now, start the passes\n",
    "            firstLayerNodes = np.ones(1)\n",
    "            for i in range(1, hiddenLayer1):\n",
    "                w = weights[\"0\"+str(i)]\n",
    "                firstLayerNodes = np.append(firstLayerNodes, sigmoid(np.dot(w, data)))\n",
    "            #Second Pass\n",
    "            secondLayerNodes = np.ones(1)\n",
    "            for j in range(1, hiddenLayer2):\n",
    "                w = weights[\"1\"+str(j)]\n",
    "                secondLayerNodes = np.append(secondLayerNodes, sigmoid(np.dot(w, firstLayerNodes)))\n",
    "            #Final pass\n",
    "            pred = np.dot(weights[\"21\"], secondLayerNodes)\n",
    "            if(updateWeights):\n",
    "                gradient = backProp(pred, label, weights, firstLayerNodes, secondLayerNodes, hiddenLayer1, hiddenLayer2, data)\n",
    "                #update weights\n",
    "                for key in weights:\n",
    "                    weights[key] = weights[key] - learningRate(gamma_0, alpha, index)*gradient[key]\n",
    "        #print(evaluateLossNN(DF, weights, hiddenLayer1, hiddenLayer2))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Width: 5\n",
      "Training: 0.9931192660550459\n",
      "Testing: 0.992\n",
      "Neural Network Width: 10\n",
      "Training: 0.9931192660550459\n",
      "Testing: 0.992\n",
      "Neural Network Width: 25\n",
      "Training: 1.0\n",
      "Testing: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = bank_note_training\n",
    "for i in range(0, 3):\n",
    "    if(i == 0):\n",
    "        hiddenLayer1 = 5\n",
    "        hiddenLayer2 = 5\n",
    "    if(i == 1):\n",
    "        hiddenLayer1 = 10\n",
    "        hiddenLayer2 = 10\n",
    "    if(i == 2):\n",
    "        hiddenLayer1 = 25\n",
    "        hiddenLayer2 = 25\n",
    "    print(\"Neural Network Width:\", hiddenLayer1)\n",
    "\n",
    "    weights = createWeightsNormal(hiddenLayer1, hiddenLayer2, data)\n",
    "    learnedWeights = forwardPass(data, weights, 10, 0.1, 25, hiddenLayer1, hiddenLayer2)\n",
    "    print(\"Training:\", evaluateNN(bank_note_training, learnedWeights, hiddenLayer1, hiddenLayer2))\n",
    "    print(\"Testing:\", evaluateNN(bank_note_testing, learnedWeights, hiddenLayer1, hiddenLayer2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
